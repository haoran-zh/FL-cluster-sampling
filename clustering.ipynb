{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import utility.dataset as dataset\n",
    "from utility.preprocessing import preprocessing\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./utility/dataset/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 27456795.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./utility/dataset/MNIST/raw/train-images-idx3-ubyte.gz to ./utility/dataset/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./utility/dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 59322083.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./utility/dataset/MNIST/raw/train-labels-idx1-ubyte.gz to ./utility/dataset/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./utility/dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 9386439.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./utility/dataset/MNIST/raw/t10k-images-idx3-ubyte.gz to ./utility/dataset/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./utility/dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 14238063.35it/s]\n",
      "/Users/alberty/Desktop/18786/FL-cluster-sampling/utility/dataset.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(dataset.targets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./utility/dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./utility/dataset/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "global_models = []\n",
    "local_results = []\n",
    "global_results = []\n",
    "tasks_data_info = []\n",
    "tasks_data_idx = []\n",
    "type_iid=[\"noniid\"]\n",
    "task_type = [\"mnist\"]\n",
    "num_clients = 20\n",
    "class_ratio=[0.21]\n",
    "class ARGS:\n",
    "    def __init__(self):\n",
    "        global num_clients\n",
    "        self.num_clients = num_clients\n",
    "        self.unbalance = [1.0, 1.0]\n",
    "\n",
    "args = ARGS()\n",
    "for i in range(len(task_type)):\n",
    "    tasks_data_info.append(preprocessing(task_type[i], data_ratio=1.0, args=args)) # 0: trainset, 1: testset, 2: min_data_num, 3: max_data_num 4: input_size, 5: classes_size\n",
    "    if type_iid[i] =='iid':\n",
    "        tasks_data_idx.append(dataset.iid(dataset=tasks_data_info[i][0],\n",
    "                                        min_data_num=tasks_data_info[i][2],\n",
    "                                        max_data_num=tasks_data_info[i][3],\n",
    "                                        num_users=num_clients)) # 0: clients_data_idx\n",
    "    elif type_iid[i] =='noniid':\n",
    "        tasks_data_idx.append(dataset.noniid(dataset=tasks_data_info[i][0],\n",
    "                            min_data_num=tasks_data_info[i][2],\n",
    "                            max_data_num=tasks_data_info[i][3],\n",
    "                            class_ratio=class_ratio[i],\n",
    "                            num_users=num_clients)) # 0: clients_data_idx 1: clients_label\n",
    "    #global_models.append(load_model(name_data=task_type[i], num_classes=tasks_data_info[i][5], args=args).to(device))\n",
    "    #local_results.append([-1,-1])\n",
    "    #global_results.append([-1,-1])\n",
    "    \n",
    "#tasks_data_idx = np.array(tasks_data_idx)\n",
    "#print(tasks_data_idx[:, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistMLP(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MnistMLP, self).__init__()\n",
    "        self.in_size = 28 * 28\n",
    "        self.hidden_size = 100\n",
    "        self.out_size = num_classes\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_features=self.in_size, out_features=self.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=self.hidden_size, out_features=self.out_size),\n",
    "        )\n",
    "        for m in self.modules():\n",
    "            if type(m) == nn.Linear:\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        batch = batch.view(batch.size(0),-1)\n",
    "        return torch.squeeze(self.net(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client:\n",
    "    def __init__(self, client_index, batch_size=128, tasks_index=0):\n",
    "        global tasks_data_info, tasks_data_idx\n",
    "        self.client_index = client_index\n",
    "        self.tasks_data_info = tasks_data_info\n",
    "        self.tasks_data_idx = tasks_data_idx\n",
    "        self.batch_size = batch_size\n",
    "        self.tasks_index = tasks_index # 0 is non-iid\n",
    "        self.set_data()\n",
    "        \n",
    "        self.model = MnistMLP()\n",
    "        self.device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "        self.training()\n",
    "        print(f\"Client {client_index}; labels {self.non_iid_labels}; accuracy {np.round(self.get_training_accuracy(), 3)}\")\n",
    "        self.get_trained_weights()\n",
    "        \n",
    "    def set_data(self):\n",
    "        if type_iid[self.tasks_index] == 'iid':\n",
    "            client_data = Subset(self.tasks_data_info[self.tasks_index][0], \n",
    "                                 self.tasks_data_idx[self.tasks_index][self.client_index])  # or iid_partition depending on your choice\n",
    "        elif type_iid[self.tasks_index] == 'noniid':\n",
    "            client_data = Subset(self.tasks_data_info[self.tasks_index][0], \n",
    "                                 self.tasks_data_idx[self.tasks_index][0][self.client_index])  # or iid_partition depending on your choice\n",
    "            self.non_iid_labels = self.tasks_data_idx[self.tasks_index][1][self.client_index]\n",
    "        self.loader = DataLoader(client_data, batch_size=self.batch_size, shuffle=True)\n",
    "    \n",
    "    \n",
    "    def training(self, epochs=10):\n",
    "        loader = self.loader\n",
    "        self.model.to(self.device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)\n",
    "        for _ in range(epochs):\n",
    "            self.model.train()\n",
    "            loss = 0\n",
    "            for i, (data, target) in enumerate(loader):\n",
    "                optimizer.zero_grad()\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                output = self.model(data)\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                loss += loss.item()\n",
    "        return self.model\n",
    "    \n",
    "    def get_training_accuracy(self):\n",
    "        self.model.to(self.device)\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in self.loader:\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                outputs = self.model(data)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += target.size(0)\n",
    "                correct += (predicted == target).sum().item()\n",
    "        return correct / total\n",
    "    \n",
    "    def get_trained_weights(self):\n",
    "        # get weights\n",
    "        self.weights = []\n",
    "        for param in self.model.parameters():\n",
    "            self.weights.append(param.data.cpu().numpy())\n",
    "        self.flattened_weights = np.concatenate([w.flatten() for w in self.weights])\n",
    "        # get graidents\n",
    "        self.gradients = []\n",
    "        for p in self.model.parameters():\n",
    "            self.gradients.append(p.grad.data.cpu().numpy())\n",
    "        self.flattened_gradients = np.concatenate([g.flatten() for g in self.gradients])\n",
    "        # get gradident norms\n",
    "        self.gradient_norms = [np.linalg.norm(g) for g in self.gradients]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cluster:\n",
    "    def __init__(self, clients, num_clusters=5):\n",
    "        self.clients = clients\n",
    "        self.num_clusters = num_clusters\n",
    "        self.cluster()\n",
    "        \n",
    "    def cluster(self, method=\"gradient_norm\"):\n",
    "        #self.client_weights = np.array([c.flattened_weights for c in self.clients])\n",
    "        #self.client_gradients = np.array([c.flattened_gradients for c in self.clients])\n",
    "        self.client_norms = np.array([c.gradient_norms for c in self.clients])\n",
    "        self.data = self.client_norms\n",
    "        \n",
    "        self.pca = PCA(n_components=2)\n",
    "        self.client_pca = self.pca.fit_transform(self.data)\n",
    "        self.kmeans = KMeans(n_clusters=self.num_clusters)\n",
    "        self.kmeans.fit(self.client_pca)\n",
    "        self.cluster_labels = self.kmeans.labels_\n",
    "        self.cluster_centers = self.kmeans.cluster_centers_\n",
    "        self.plot()\n",
    "        \n",
    "    def plot(self):\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        for i in range(self.num_clusters):\n",
    "            plt.scatter(self.client_pca[self.cluster_labels == i, 0], \n",
    "                        self.client_pca[self.cluster_labels == i, 1], \n",
    "                        label=f'Cluster {i}')\n",
    "        for i, (x, y) in enumerate(self.client_pca):\n",
    "            plt.annotate(f'Client {i}; labels {self.clients[i].non_iid_labels}', \n",
    "                         (x, y), \n",
    "                         textcoords=\"offset points\", \n",
    "                         xytext=(0,10), \n",
    "                         ha='center')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    def get_result(self):\n",
    "        return pd.DataFrame({\"cluster_labels\": self.cluster_labels, \n",
    "                             \"client_index\": [c.client_index for c in self.clients]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0; labels [1, 7]; accuracy 0.995\n",
      "Client 1; labels [1, 3]; accuracy 0.99\n",
      "Client 2; labels [1, 7]; accuracy 0.987\n",
      "Client 3; labels [2, 9]; accuracy 0.996\n",
      "Client 4; labels [1, 0]; accuracy 1.0\n",
      "Client 5; labels [6, 3]; accuracy 1.0\n",
      "Client 6; labels [8, 4]; accuracy 0.993\n",
      "Client 7; labels [7, 2]; accuracy 0.993\n",
      "Client 8; labels [9, 1]; accuracy 0.993\n",
      "Client 9; labels [0, 6]; accuracy 0.995\n",
      "Client 10; labels [3, 8]; accuracy 0.987\n",
      "Client 11; labels [4, 5]; accuracy 0.997\n",
      "Client 12; labels [7, 9]; accuracy 0.972\n",
      "Client 13; labels [1, 2]; accuracy 0.992\n",
      "Client 14; labels [0, 6]; accuracy 0.993\n",
      "Client 15; labels [3, 8]; accuracy 0.976\n",
      "Client 16; labels [4, 7]; accuracy 0.996\n",
      "Client 17; labels [5, 1]; accuracy 0.994\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch (got input: [10], target: [1])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m clients \u001b[38;5;241m=\u001b[39m [Client(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_clients)]\n\u001b[1;32m      2\u001b[0m c \u001b[38;5;241m=\u001b[39m Cluster(clients)\n",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m clients \u001b[38;5;241m=\u001b[39m [\u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_clients)]\n\u001b[1;32m      2\u001b[0m c \u001b[38;5;241m=\u001b[39m Cluster(clients)\n",
      "Cell \u001b[0;32mIn[10], line 13\u001b[0m, in \u001b[0;36mClient.__init__\u001b[0;34m(self, client_index, batch_size, tasks_index)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m MnistMLP()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mmps\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClient \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; labels \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnon_iid_labels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; accuracy \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_training_accuracy(),\u001b[38;5;250m \u001b[39m\u001b[38;5;241m3\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_trained_weights()\n",
      "Cell \u001b[0;32mIn[10], line 40\u001b[0m, in \u001b[0;36mClient.training\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m     38\u001b[0m data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), target\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     39\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(data)\n\u001b[0;32m---> 40\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     42\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniforge3/envs/hlagent/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/hlagent/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/hlagent/lib/python3.10/site-packages/torch/nn/modules/loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/hlagent/lib/python3.10/site-packages/torch/nn/functional.py:3053\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3052\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch (got input: [10], target: [1])"
     ]
    }
   ],
   "source": [
    "clients = [Client(i) for i in range(num_clients)]\n",
    "c = Cluster(clients)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
