{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import utility.dataset as dataset\n",
    "from utility.preprocessing import preprocessing\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haoranzhang/Downloads/FL-cluster-sampling/utility/dataset.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(dataset.targets)\n"
     ]
    }
   ],
   "source": [
    "global_models = []\n",
    "local_results = []\n",
    "global_results = []\n",
    "tasks_data_info = []\n",
    "tasks_data_idx = []\n",
    "\n",
    "# experiment settings\n",
    "type_iid=[\"noniid\"]\n",
    "task_type = [\"mnist\"]\n",
    "num_clients = 20\n",
    "class_ratio=[0.21]\n",
    "active_rate = 0.2\n",
    "class ARGS:\n",
    "    def __init__(self):\n",
    "        global num_clients\n",
    "        self.num_clients = num_clients\n",
    "        self.unbalance = [1.0, 1.0]  # [0]% of clients have [1]% of data\n",
    "args = ARGS()\n",
    "random_seed = 18796\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(task_type)):\n",
    "    tasks_data_info.append(preprocessing(task_type[i], data_ratio=1.0, args=args)) # 0: trainset, 1: testset, 2: min_data_num, 3: max_data_num 4: input_size, 5: classes_size\n",
    "    if type_iid[i] =='iid':\n",
    "        tasks_data_idx.append(dataset.iid(dataset=tasks_data_info[i][0],\n",
    "                                        min_data_num=tasks_data_info[i][2],\n",
    "                                        max_data_num=tasks_data_info[i][3],\n",
    "                                        num_users=num_clients)) # 0: clients_data_idx\n",
    "    elif type_iid[i] =='noniid':\n",
    "        tasks_data_idx.append(dataset.noniid(dataset=tasks_data_info[i][0],\n",
    "                            min_data_num=tasks_data_info[i][2],\n",
    "                            max_data_num=tasks_data_info[i][3],\n",
    "                            class_ratio=class_ratio[i],\n",
    "                            num_users=num_clients))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient(weights_this_round, weights_next_round): \n",
    "    # get gradient by subtracting weights_next_round from weights_this_round\n",
    "    weight_diff = {name: (weights_this_round[name] - weights_next_round[name]).cpu() for name in weights_this_round}\n",
    "    return weight_diff\n",
    "\n",
    "def loss_sampling(m, clients):\n",
    "    # sample m clients with lowest accuracy\n",
    "    acc_list = []\n",
    "    for i in range(len(clients)):\n",
    "        acc_list.append(clients[i].get_training_accuracy())\n",
    "    acc_list = np.array(acc_list)\n",
    "    idx = np.argsort(acc_list)\n",
    "    idx = idx[:m]\n",
    "    active_clients = [clients[i] for i in idx]\n",
    "    return active_clients\n",
    "\n",
    "def cluster_sampling(active_num, clients, cluster_result):\n",
    "    len_cluster = [len(cluster) for cluster in cluster_result]\n",
    "    client_num  = len(clients)\n",
    "    active_num_cluster = [int(active_num * len_cluster[i] / client_num) for i in range(len(len_cluster))]\n",
    "    active_clients_list = []\n",
    "    for i, cluster_clients in enumerate(cluster_result):\n",
    "        active_clients_list.extend(loss_sampling(m=active_num_cluster[i], clients=cluster_clients))\n",
    "\n",
    "    return active_clients_list\n",
    "\n",
    "def flatten_params(state_dict):\n",
    "    flattened_weights = np.concatenate([param.flatten() for param in state_dict])\n",
    "    return flattened_weights\n",
    "\n",
    "def cosine_similarity(state_dict1, state_dict2):\n",
    "    \"\"\"Compute the cosine similarity between two model state dictionaries.\"\"\"\n",
    "    vec1 = flatten_params(state_dict1)\n",
    "    vec2 = flatten_params(state_dict2)\n",
    "    # convert vec1 and vec2 to torch tensors\n",
    "    vec1 = torch.tensor(vec1)\n",
    "    vec2 = torch.tensor(vec2)\n",
    "    dot_product = torch.dot(vec1, vec2)\n",
    "    norm1 = torch.norm(vec1)\n",
    "    norm2 = torch.norm(vec2)\n",
    "    if norm1 > 0 and norm2 > 0:\n",
    "        return dot_product / (norm1 * norm2)\n",
    "    else:\n",
    "        return 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistMLP(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MnistMLP, self).__init__()\n",
    "        self.in_size = 28 * 28\n",
    "        self.hidden_size = 100\n",
    "        self.out_size = num_classes\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_features=self.in_size, out_features=self.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=self.hidden_size, out_features=self.out_size),\n",
    "        )\n",
    "        for m in self.modules():\n",
    "            if type(m) == nn.Linear:\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        batch = batch.view(batch.size(0),-1)\n",
    "        return torch.squeeze(self.net(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client:\n",
    "    def __init__(self, client_index, batch_size=256, tasks_index=0):\n",
    "        global tasks_data_info, tasks_data_idx\n",
    "        self.client_index = client_index\n",
    "        self.tasks_data_info = tasks_data_info\n",
    "        self.tasks_data_idx = tasks_data_idx\n",
    "        self.batch_size = batch_size\n",
    "        self.tasks_index = tasks_index # 0 is non-iid\n",
    "        self.gradient = None\n",
    "        self.set_data()\n",
    "        self.model = MnistMLP()\n",
    "        self.device = torch.device(\"cpu\")\n",
    "        self.training(epochs=10)\n",
    "        print(f\"Client {client_index}; labels {self.non_iid_labels}; accuracy {np.round(self.get_training_accuracy(), 3)}\")\n",
    "        self.get_trained_weights()\n",
    "\n",
    "        local_data_num = []\n",
    "        for client_idx in range(num_clients):\n",
    "            local_data_num.append(len(tasks_data_idx[self.tasks_index][0][client_idx]))\n",
    "        self.data_fraction = len(self.loader.dataset) / sum(local_data_num)\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "    def set_data(self):\n",
    "        if type_iid[self.tasks_index] == 'iid':\n",
    "            client_data = Subset(self.tasks_data_info[self.tasks_index][0], \n",
    "                                 self.tasks_data_idx[self.tasks_index][self.client_index])  # or iid_partition depending on your choice\n",
    "        elif type_iid[self.tasks_index] == 'noniid':\n",
    "            client_data = Subset(self.tasks_data_info[self.tasks_index][0], \n",
    "                                 self.tasks_data_idx[self.tasks_index][0][self.client_index])  # or iid_partition depending on your choice\n",
    "            self.non_iid_labels = self.tasks_data_idx[self.tasks_index][1][self.client_index]\n",
    "        self.loader = DataLoader(client_data, batch_size=self.batch_size, shuffle=True, drop_last=True)\n",
    "    \n",
    "    \n",
    "    def training(self, epochs=10):\n",
    "        loader = self.loader\n",
    "        self.model.to(self.device)\n",
    "        previous_local_state_dict = self.model.state_dict().copy()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)\n",
    "\n",
    "        client_label = tasks_data_idx[self.tasks_index][1][self.client_index]\n",
    "\n",
    "\n",
    "        for _ in range(epochs):\n",
    "            self.model.train()\n",
    "            loss = 0\n",
    "            for i, (data, target) in enumerate(loader):\n",
    "                optimizer.zero_grad()\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                output = self.model(data)\n",
    "\n",
    "                label_mask = torch.zeros(tasks_data_info[self.tasks_index][5], device=output.device)\n",
    "                label_mask[client_label] = 1\n",
    "                output = output.masked_fill(label_mask == 0, 0)\n",
    "                     \n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                loss += loss.item()\n",
    "        self.gradients = get_gradient(previous_local_state_dict, self.model.state_dict())\n",
    "        return self.model\n",
    "    \n",
    "    def get_training_accuracy(self):\n",
    "        self.model.to(self.device)\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in self.loader:\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                outputs = self.model(data)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += target.size(0)\n",
    "                correct += (predicted == target).sum().item()\n",
    "        return correct / total\n",
    "    \n",
    "    def get_trained_weights(self):\n",
    "        # get weights\n",
    "        self.weights = []\n",
    "        for param in self.model.parameters():\n",
    "            self.weights.append(param.data.cpu().numpy())\n",
    "        self.flattened_weights = np.concatenate([w.flatten() for w in self.weights])\n",
    "        # get graidents\n",
    "        self.gradients = []\n",
    "        for p in self.model.parameters():\n",
    "            self.gradients.append(p.grad.data.cpu().numpy())\n",
    "        self.flattened_gradients = np.concatenate([g.flatten() for g in self.gradients])\n",
    "        # get gradident norms\n",
    "        self.gradient_norms = [np.linalg.norm(g) for g in self.gradients]\n",
    "\n",
    "    def update_to_global_weights(self, global_model):\n",
    "        self.model.load_state_dict(global_model.state_dict())\n",
    "    \n",
    "    def get_local_weights(self):\n",
    "        return self.model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cluster:\n",
    "    def __init__(self, clients, num_clusters=5):\n",
    "        self.clients = clients\n",
    "        self.num_clusters = num_clusters\n",
    "        # self.cluster()\n",
    "        \n",
    "    def cluster(self, method=\"gradient_norm\"):\n",
    "        #self.client_weights = np.array([c.flattened_weights for c in self.clients])\n",
    "        #self.client_gradients = np.array([c.flattened_gradients for c in self.clients])\n",
    "        #for c in self.clients:\n",
    "        #    c.get_trained_weights()\n",
    "\n",
    "        # try to use gradient similarity\n",
    "        if method == \"cosine\":\n",
    "            from sklearn.cluster import SpectralClustering\n",
    "            gradient_similarity = np.ones((len(self.clients), len(self.clients)))\n",
    "            for i in range(len(self.clients)):\n",
    "                for j in range(i+1, len(self.clients)):\n",
    "                    gradient_i = self.clients[i].gradients\n",
    "                    gradient_j = self.clients[j].gradients\n",
    "                    gradient_similarity[i, j] = cosine_similarity(gradient_i, gradient_j)\n",
    "                    gradient_similarity[j, i] = gradient_similarity[i, j]\n",
    "            print(gradient_similarity)\n",
    "            clustering = SpectralClustering(n_clusters=self.num_clusters,\n",
    "                                    affinity='precomputed',\n",
    "                                    assign_labels='kmeans',\n",
    "                                    random_state=0).fit(gradient_similarity)\n",
    "            self.cluster_labels = clustering.labels_\n",
    "        else:\n",
    "            self.client_norms = np.array([c.gradient_norms for c in self.clients])\n",
    "            self.data = self.client_norms\n",
    "            self.pca = PCA(n_components=2)\n",
    "            self.client_pca = self.pca.fit_transform(self.data)\n",
    "            self.kmeans = KMeans(n_clusters=self.num_clusters)\n",
    "            self.kmeans.fit(self.client_pca)\n",
    "            self.cluster_labels = self.kmeans.labels_\n",
    "            self.cluster_centers = self.kmeans.cluster_centers_\n",
    "            # self.plot()\n",
    "        \n",
    "    def plot(self):\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        for i in range(self.num_clusters):\n",
    "            plt.scatter(self.client_pca[self.cluster_labels == i, 0], \n",
    "                        self.client_pca[self.cluster_labels == i, 1], \n",
    "                        label=f'Cluster {i}')\n",
    "        for i, (x, y) in enumerate(self.client_pca):\n",
    "            plt.annotate(f'Client {i}; labels {self.clients[i].non_iid_labels}', \n",
    "                         (x, y), \n",
    "                         textcoords=\"offset points\", \n",
    "                         xytext=(0,10), \n",
    "                         ha='center')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    def get_result(self):\n",
    "        #return pd.DataFrame({\"cluster_labels\": self.cluster_labels, \n",
    "        #                     \"client_index\": [c.client_index for c in self.clients]})\n",
    "        cluster_clients_list = []\n",
    "        for cluster in range(self.num_clusters):\n",
    "            cluster_clients_list.append([])\n",
    "            # initialize cluster_clients_list\n",
    "\n",
    "        for c in self.clients:\n",
    "            c_index = c.client_index\n",
    "            cluster = self.cluster_labels[c_index]\n",
    "            cluster_clients_list[cluster].append(c)\n",
    "        self.result = cluster_clients_list\n",
    "        return self.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0; labels [1, 7]; accuracy 0.99\n",
      "Client 1; labels [1, 3]; accuracy 0.979\n",
      "Client 2; labels [1, 7]; accuracy 0.975\n",
      "Client 3; labels [2, 9]; accuracy 0.984\n",
      "Client 4; labels [1, 0]; accuracy 0.998\n",
      "Client 5; labels [6, 3]; accuracy 0.996\n",
      "Client 6; labels [8, 4]; accuracy 0.984\n",
      "Client 7; labels [7, 2]; accuracy 0.984\n",
      "Client 8; labels [1, 9]; accuracy 0.99\n",
      "Client 9; labels [0, 6]; accuracy 0.984\n",
      "finish cluster\n"
     ]
    }
   ],
   "source": [
    "num_clients = 10\n",
    "clients = [Client(i) for i in range(num_clients)]\n",
    "c = Cluster(clients)\n",
    "c.cluster()\n",
    "print('finish cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Server:\n",
    "    def __init__(self, batch_size=128, tasks_index=0):\n",
    "        global tasks_data_info, tasks_data_idx\n",
    "        self.tasks_data_info = tasks_data_info\n",
    "        self.tasks_data_idx = tasks_data_idx\n",
    "        self.batch_size = batch_size\n",
    "        self.tasks_index = tasks_index # 0 is non-iid\n",
    "        self.test_data = self.tasks_data_info[self.tasks_index][1] # set test dataset\n",
    "        self.loss_list = []\n",
    "        \n",
    "        self.global_model = MnistMLP()\n",
    "        self.device = torch.device(\"cpu\")\n",
    "        #self.training()\n",
    "        #self.get_trained_weights()\n",
    "        # load global model\n",
    "\n",
    "    def aggregation(self):\n",
    "        # aggregate weights\n",
    "        global_weights_state_dict = self.global_model.state_dict()\n",
    "        global_keys = list(global_weights_state_dict.keys())\n",
    "        for key in global_keys:\n",
    "            global_weights_state_dict[key] = torch.zeros_like(global_weights_state_dict[key])\n",
    "\n",
    "        fraction_sum = 0\n",
    "        for c in self.active_clients:\n",
    "            fraction_sum += c.data_fraction\n",
    "\n",
    "        for c in self.active_clients:\n",
    "            for key in global_weights_state_dict.keys():\n",
    "                global_weights_state_dict[key] += c.data_fraction / fraction_sum * c.model.state_dict()[key]\n",
    "\n",
    "        # update global model\n",
    "        self.global_model.load_state_dict(global_weights_state_dict)\n",
    "\n",
    "\n",
    "    def sampling(self, clients, method='random'):\n",
    "        global active_rate\n",
    "        active_num = int(active_rate * len(clients))\n",
    "        if method == 'random':\n",
    "            self.active_clients = random.sample(clients, active_num)\n",
    "        elif method == 'IS':\n",
    "            self.active_clients = loss_sampling(m=active_num, clients=clients)\n",
    "        elif method == 'cluster':\n",
    "            clusters = Cluster(clients)\n",
    "            clusters.cluster()\n",
    "            cluster_result = clusters.get_result()\n",
    "            self.active_clients = cluster_sampling(active_num, clients, cluster_result)\n",
    "    \n",
    "    def get_global_loss(self):\n",
    "        testloader = DataLoader(self.test_data, batch_size=self.batch_size, shuffle=False)\n",
    "        self.global_model.to(self.device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loss = 0\n",
    "        with torch.no_grad():\n",
    "            for i, (data, target) in enumerate(testloader):\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                output = self.global_model(data)\n",
    "                loss += criterion(output, target)\n",
    "            loss /= len(testloader)\n",
    "        # print('global loss: ', loss.item())\n",
    "        return loss.item()\n",
    "\n",
    "        \n",
    "\n",
    "    def FL_training(self, num_clients=20, rounds=10, sampling_method='random'):\n",
    "        # define clients\n",
    "        from tqdm import tqdm\n",
    "        clients = [Client(i) for i in range(num_clients)]\n",
    "\n",
    "        for r in tqdm(range(rounds)):\n",
    "            # set local models weights to current global\n",
    "            for c in clients:\n",
    "                c.update_to_global_weights(self.global_model)\n",
    "            # sampling with current global model\n",
    "            self.sampling(clients, method=sampling_method)\n",
    "            # train clients\n",
    "            for c in self.active_clients:\n",
    "                c.training(epochs=5)\n",
    "            # aggregate weights\n",
    "            self.aggregation()\n",
    "            self.loss_list.append(self.get_global_loss())\n",
    "    \n",
    "    def plot_loss(self):\n",
    "        plt.plot(self.loss_list)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0; labels [1, 7]; accuracy 0.98\n",
      "Client 1; labels [1, 3]; accuracy 0.982\n",
      "Client 2; labels [1, 7]; accuracy 0.982\n",
      "Client 3; labels [2, 9]; accuracy 0.988\n",
      "Client 4; labels [1, 0]; accuracy 0.996\n",
      "Client 5; labels [6, 3]; accuracy 1.0\n",
      "Client 6; labels [8, 4]; accuracy 0.986\n",
      "Client 7; labels [7, 2]; accuracy 0.98\n",
      "Client 8; labels [1, 9]; accuracy 0.99\n",
      "Client 9; labels [0, 6]; accuracy 0.977\n",
      "Client 10; labels [3, 8]; accuracy 0.902\n",
      "Client 11; labels [4, 7]; accuracy 0.98\n",
      "Client 12; labels [5, 1]; accuracy 0.996\n",
      "Client 13; labels [9, 2]; accuracy 0.988\n",
      "Client 14; labels [0, 6]; accuracy 0.986\n",
      "Client 15; labels [3, 8]; accuracy 0.961\n",
      "Client 16; labels [4, 7]; accuracy 0.982\n",
      "Client 17; labels [5, 1]; accuracy 0.982\n",
      "Client 18; labels [9, 2]; accuracy 0.988\n",
      "Client 19; labels [0, 6]; accuracy 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 25/150 [01:14<07:21,  3.53s/it]"
     ]
    }
   ],
   "source": [
    "active_rate = 0.2\n",
    "server_random = Server()\n",
    "server_random.FL_training(sampling_method='random', rounds=150)\n",
    "server_random.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "server_random.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0; labels [1, 7]; accuracy 0.986\n",
      "Client 1; labels [1, 3]; accuracy 0.979\n",
      "Client 2; labels [1, 7]; accuracy 0.982\n",
      "Client 3; labels [2, 9]; accuracy 0.99\n",
      "Client 4; labels [1, 0]; accuracy 0.998\n",
      "Client 5; labels [6, 3]; accuracy 0.992\n",
      "Client 6; labels [8, 4]; accuracy 0.98\n",
      "Client 7; labels [7, 2]; accuracy 0.979\n",
      "Client 8; labels [1, 9]; accuracy 0.988\n",
      "Client 9; labels [0, 6]; accuracy 0.979\n",
      "Client 10; labels [3, 8]; accuracy 0.953\n",
      "Client 11; labels [4, 7]; accuracy 0.986\n",
      "Client 12; labels [5, 1]; accuracy 0.99\n",
      "Client 13; labels [9, 2]; accuracy 0.982\n",
      "Client 14; labels [0, 6]; accuracy 0.986\n",
      "Client 15; labels [3, 8]; accuracy 0.961\n",
      "Client 16; labels [4, 7]; accuracy 0.988\n",
      "Client 17; labels [5, 1]; accuracy 0.988\n",
      "Client 18; labels [9, 2]; accuracy 0.99\n",
      "Client 19; labels [0, 6]; accuracy 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/150 [00:04<10:26,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  8.073247909545898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 2/150 [00:08<10:39,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  5.0097527503967285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/150 [00:12<10:25,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  3.2135097980499268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4/150 [00:17<10:29,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  2.298682928085327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 5/150 [00:21<10:14,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  1.9970043897628784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 6/150 [00:25<10:14,  4.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  1.592970848083496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 7/150 [00:29<10:08,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  1.5983498096466064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 8/150 [00:34<10:06,  4.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  1.4328824281692505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 9/150 [00:38<09:52,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  1.0968838930130005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 10/150 [00:42<09:48,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  1.1079200506210327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 11/150 [00:46<09:45,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  1.1093961000442505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 12/150 [00:50<09:41,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  1.0201911926269531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 13/150 [00:55<09:47,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.9511577486991882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 14/150 [00:59<09:55,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.9675657153129578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 15/150 [01:04<09:49,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.9668163657188416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 16/150 [01:08<09:58,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.95366370677948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 17/150 [01:13<10:13,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.9769615530967712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 18/150 [01:18<09:48,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.8893016576766968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 19/150 [01:22<09:39,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.8964065313339233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 20/150 [01:26<09:31,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.9259937405586243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 21/150 [01:30<09:17,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.9257574677467346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 22/150 [01:34<09:07,  4.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.870146632194519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 23/150 [01:39<08:56,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.8757182955741882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 24/150 [01:43<08:45,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.8509498238563538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 25/150 [01:47<08:40,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.8409050107002258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 26/150 [01:51<08:34,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.8535673022270203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 27/150 [01:55<08:27,  4.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.8278466463088989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 28/150 [01:59<08:20,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.8166224956512451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 29/150 [02:03<08:16,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.8465278744697571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 30/150 [02:07<08:08,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.8063057661056519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 31/150 [02:11<08:01,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.8009342551231384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 32/150 [02:15<07:56,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.8096228241920471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 33/150 [02:19<07:49,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.8147608041763306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 34/150 [02:23<07:50,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.8135939240455627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 35/150 [02:27<07:50,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.8256155252456665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 36/150 [02:31<07:41,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7807336449623108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 37/150 [02:35<07:36,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7787925004959106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 38/150 [02:39<07:33,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.772341251373291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 39/150 [02:44<07:36,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7774603962898254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 40/150 [02:48<07:32,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7905665636062622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 41/150 [02:52<07:31,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7456615567207336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 42/150 [02:56<07:34,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7862778902053833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 43/150 [03:01<07:29,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7685865759849548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 44/150 [03:05<07:28,  4.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.9429154396057129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 45/150 [03:09<07:19,  4.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.8399046659469604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 46/150 [03:13<07:13,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.8088247776031494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 47/150 [03:17<07:05,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7675451040267944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 48/150 [03:21<07:00,  4.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7973426580429077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 49/150 [03:25<06:53,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7963600754737854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 50/150 [03:29<06:47,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.8176308274269104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 51/150 [03:33<06:44,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7909066677093506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 52/150 [03:37<06:39,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7725502848625183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 53/150 [03:42<06:46,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7857705950737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 54/150 [03:46<06:45,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7773283123970032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 55/150 [03:50<06:42,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7668699026107788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 56/150 [03:55<06:33,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.761746883392334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 57/150 [03:59<06:30,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7662644982337952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 58/150 [04:03<06:21,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7634164690971375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 59/150 [04:07<06:19,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7570247650146484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 60/150 [04:11<06:13,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7609069347381592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 61/150 [04:15<06:12,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7489675879478455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 62/150 [04:20<06:09,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.745478093624115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 63/150 [04:24<06:06,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7364742159843445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 64/150 [04:28<06:03,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7615169882774353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 65/150 [04:32<05:59,  4.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7620843648910522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 66/150 [04:36<05:52,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7838169932365417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 67/150 [04:41<05:49,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7481145262718201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 68/150 [04:45<05:39,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7428260445594788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 69/150 [04:49<05:31,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.751467764377594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 70/150 [04:53<05:24,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7361177802085876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 71/150 [04:57<05:21,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7892107963562012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 72/150 [05:01<05:18,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7738343477249146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 73/150 [05:05<05:13,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7603325247764587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 74/150 [05:09<05:14,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.800471305847168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 75/150 [05:13<05:11,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7883395552635193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 76/150 [05:18<05:06,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7932830452919006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 77/150 [05:22<05:06,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7838357090950012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 78/150 [05:27<05:13,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7955312132835388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 79/150 [05:31<05:04,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7639784812927246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 80/150 [05:35<04:59,  4.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7846370339393616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 81/150 [05:39<04:56,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.8199858665466309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 82/150 [05:43<04:49,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7956216335296631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 83/150 [05:48<04:45,  4.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.768500566482544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 84/150 [05:52<04:41,  4.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7699441313743591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 85/150 [05:56<04:37,  4.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7610149383544922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 86/150 [06:01<04:32,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.76760333776474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 87/150 [06:05<04:28,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7792513966560364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 88/150 [06:09<04:24,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7716088891029358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 89/150 [06:13<04:16,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7492592930793762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 90/150 [06:17<04:12,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7380741238594055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 91/150 [06:21<04:07,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.756243109703064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 92/150 [06:26<04:04,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7556070685386658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 93/150 [06:30<04:01,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7639699578285217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 94/150 [06:34<03:56,  4.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7778759002685547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 95/150 [06:38<03:50,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7642713785171509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 96/150 [06:42<03:45,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7953630089759827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 97/150 [06:47<03:42,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.8027268052101135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 98/150 [06:51<03:36,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7488612532615662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 99/150 [06:55<03:33,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7670945525169373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 100/150 [06:59<03:27,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7761968970298767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 101/150 [07:03<03:22,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7872139811515808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 102/150 [07:07<03:20,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7408398389816284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 103/150 [07:12<03:14,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7544795870780945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 104/150 [07:16<03:12,  4.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.8076773285865784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 105/150 [07:20<03:06,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7982239723205566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 106/150 [07:24<03:04,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7793570756912231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 107/150 [07:28<02:58,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.8018081784248352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 108/150 [07:32<02:52,  4.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7784925699234009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 109/150 [07:36<02:48,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7636172771453857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 110/150 [07:40<02:43,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7539073824882507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 111/150 [07:44<02:39,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7445380091667175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 112/150 [07:49<02:35,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7783679962158203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 113/150 [07:53<02:30,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.9129621386528015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 114/150 [07:57<02:27,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.8441926836967468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 115/150 [08:01<02:24,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.8184911012649536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 116/150 [08:05<02:21,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.8332954049110413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 117/150 [08:09<02:17,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.85831618309021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 118/150 [08:14<02:14,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7972467541694641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 119/150 [08:18<02:09,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7990476489067078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 120/150 [08:22<02:04,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.8188803791999817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 121/150 [08:26<02:03,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.8345527052879333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 122/150 [08:30<01:57,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.838875412940979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 123/150 [08:35<01:52,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.8446353077888489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 124/150 [08:39<01:47,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.8110273480415344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 125/150 [08:43<01:43,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.8088794946670532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 126/150 [08:47<01:39,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7926878333091736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 127/150 [08:51<01:34,  4.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.8014445304870605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 128/150 [08:55<01:30,  4.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7938887476921082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 129/150 [08:59<01:26,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.8279644250869751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 130/150 [09:03<01:23,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7913084030151367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 131/150 [09:08<01:18,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7903922200202942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 132/150 [09:12<01:13,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.8196864128112793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 133/150 [09:16<01:09,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.8085368871688843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 134/150 [09:20<01:05,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7918688654899597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 135/150 [09:24<01:01,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7788731455802917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 136/150 [09:28<00:58,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7719494104385376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 137/150 [09:32<00:53,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.8036072850227356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 138/150 [09:36<00:49,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.806823194026947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 139/150 [09:41<00:46,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7722642421722412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 140/150 [09:45<00:41,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7739134430885315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 141/150 [09:49<00:37,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7639303803443909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 142/150 [09:53<00:32,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7759432792663574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 143/150 [09:57<00:28,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.8109017610549927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 144/150 [10:01<00:24,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.8051080107688904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 145/150 [10:05<00:20,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.8331236243247986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 146/150 [10:09<00:16,  4.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.8475609421730042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 147/150 [10:13<00:12,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7996265292167664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 148/150 [10:18<00:08,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.7907260060310364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 149/150 [10:22<00:04,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.8275590538978577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [10:26<00:00,  4.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  0.8808903694152832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_rate = 0.2\n",
    "server_IS = Server()\n",
    "server_IS.FL_training(sampling_method='IS', rounds=150)\n",
    "server_IS.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(server_IS.loss_list, label='IS')\n",
    "plt.plot(server_random.loss_list, label='random')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0; labels [1, 7]; accuracy 0.986\n",
      "Client 1; labels [1, 3]; accuracy 0.984\n",
      "Client 2; labels [1, 7]; accuracy 0.982\n",
      "Client 3; labels [2, 9]; accuracy 0.98\n",
      "Client 4; labels [1, 0]; accuracy 0.998\n",
      "Client 5; labels [6, 3]; accuracy 0.99\n",
      "Client 6; labels [8, 4]; accuracy 0.984\n",
      "Client 7; labels [7, 2]; accuracy 0.984\n",
      "Client 8; labels [1, 9]; accuracy 0.988\n",
      "Client 9; labels [0, 6]; accuracy 0.992\n",
      "Client 10; labels [3, 8]; accuracy 0.922\n",
      "Client 11; labels [4, 7]; accuracy 0.984\n",
      "Client 12; labels [5, 1]; accuracy 0.992\n",
      "Client 13; labels [9, 2]; accuracy 0.982\n",
      "Client 14; labels [0, 6]; accuracy 0.994\n",
      "Client 15; labels [3, 8]; accuracy 0.957\n",
      "Client 16; labels [4, 7]; accuracy 0.988\n",
      "Client 17; labels [5, 1]; accuracy 0.979\n",
      "Client 18; labels [9, 2]; accuracy 0.994\n",
      "Client 19; labels [0, 6]; accuracy 0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/150 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/150 [00:03<08:39,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  6.325581073760986\n",
      "pca finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 2/150 [00:06<08:32,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global loss:  3.37813663482666\n",
      "pca finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 2/150 [00:08<09:58,  4.05s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [18]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m active_rate \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.2\u001B[39m\n\u001B[1;32m      2\u001B[0m server_cluster \u001B[38;5;241m=\u001B[39m Server()\n\u001B[0;32m----> 3\u001B[0m \u001B[43mserver_cluster\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mFL_training\u001B[49m\u001B[43m(\u001B[49m\u001B[43msampling_method\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcluster\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m150\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m server_cluster\u001B[38;5;241m.\u001B[39mplot_loss()\n",
      "Input \u001B[0;32mIn [17]\u001B[0m, in \u001B[0;36mServer.FL_training\u001B[0;34m(self, num_clients, rounds, sampling_method)\u001B[0m\n\u001B[1;32m     73\u001B[0m     c\u001B[38;5;241m.\u001B[39mupdate_to_global_weights(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mglobal_model)\n\u001B[1;32m     74\u001B[0m \u001B[38;5;66;03m# sampling with current global model\u001B[39;00m\n\u001B[0;32m---> 75\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msampling\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclients\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msampling_method\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     76\u001B[0m \u001B[38;5;66;03m# train clients\u001B[39;00m\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m c \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mactive_clients:\n",
      "Input \u001B[0;32mIn [17]\u001B[0m, in \u001B[0;36mServer.sampling\u001B[0;34m(self, clients, method)\u001B[0m\n\u001B[1;32m     45\u001B[0m clusters\u001B[38;5;241m.\u001B[39mcluster()\n\u001B[1;32m     46\u001B[0m cluster_result \u001B[38;5;241m=\u001B[39m clusters\u001B[38;5;241m.\u001B[39mget_result()\n\u001B[0;32m---> 47\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mactive_clients \u001B[38;5;241m=\u001B[39m \u001B[43mcluster_sampling\u001B[49m\u001B[43m(\u001B[49m\u001B[43mactive_num\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclients\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcluster_result\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[0;32mIn [13]\u001B[0m, in \u001B[0;36mcluster_sampling\u001B[0;34m(active_num, clients, cluster_result)\u001B[0m\n\u001B[1;32m     21\u001B[0m active_clients_list \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, cluster_clients \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(cluster_result):\n\u001B[0;32m---> 23\u001B[0m     active_clients_list\u001B[38;5;241m.\u001B[39mextend(\u001B[43mloss_sampling\u001B[49m\u001B[43m(\u001B[49m\u001B[43mm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mactive_num_cluster\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclients\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcluster_clients\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m active_clients_list\n",
      "Input \u001B[0;32mIn [13]\u001B[0m, in \u001B[0;36mloss_sampling\u001B[0;34m(m, clients)\u001B[0m\n\u001B[1;32m      8\u001B[0m acc_list \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(clients)):\n\u001B[0;32m---> 10\u001B[0m     acc_list\u001B[38;5;241m.\u001B[39mappend(\u001B[43mclients\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_training_accuracy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     11\u001B[0m acc_list \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(acc_list)\n\u001B[1;32m     12\u001B[0m idx \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margsort(acc_list)\n",
      "Input \u001B[0;32mIn [8]\u001B[0m, in \u001B[0;36mClient.get_training_accuracy\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     70\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m data, target \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloader:\n\u001B[1;32m     71\u001B[0m     data, target \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice), target\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m---> 72\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     73\u001B[0m     _, predicted \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmax(outputs\u001B[38;5;241m.\u001B[39mdata, \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     74\u001B[0m     total \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m target\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Input \u001B[0;32mIn [7]\u001B[0m, in \u001B[0;36mMnistMLP.forward\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch):\n\u001B[1;32m     17\u001B[0m     batch \u001B[38;5;241m=\u001B[39m batch\u001B[38;5;241m.\u001B[39mview(batch\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m),\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m---> 18\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnet\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 217\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/linear.py:116\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 116\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "active_rate = 0.2\n",
    "server_cluster = Server()\n",
    "server_cluster.FL_training(sampling_method='cluster', rounds=150)\n",
    "server_cluster.plot_loss()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
